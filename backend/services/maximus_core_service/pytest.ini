[pytest]
# Test discovery
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Output and reporting
addopts =
    --verbose
    --tb=short
    --cov=.
    --cov-report=html:htmlcov
    --cov-report=term-missing
    --cov-report=xml
    --cov-fail-under=70
    -ra
    --color=yes
    --ignore=tests/archived_broken
    --ignore=tests/archived_v4_tests
    --ignore=tests/unit/consciousness/archived_safety_tests
    --ignore=tests/unit/consciousness/archived_broken_fixtures
    --ignore=tests/unit/consciousness/archived_obsolete_api
    --ignore=tests/unit/test_controller_old_v3.py
    --ignore=tests/unit/test_coordinator_old_unit.py
    --ignore=tests/unit/test_coordinator_old_v3.py
    --ignore=tests/unit/test_esgt_subscriber_v3.py
    --ignore=tests/unit/test_fabric_old_unit.py
    --ignore=tests/unit/test_fabric_old_v3.py
    --ignore=tests/unit/test_mcea_client_v3.py
    --ignore=tests/unit/test_mea_bridge_unit.py
    --ignore=tests/unit/test_mea_bridge_v3.py
    --ignore=tests/unit/test_mmei_client_v3.py
    --ignore=tests/unit/test_monitor_old_v3.py
    --ignore=tests/unit/test_sensory_esgt_bridge_v3.py
    --ignore=tests/integration/consciousness/test_immune_consciousness_integration.py
    --ignore=tests/integration/consciousness/test_integration_100pct.py
    --ignore=tests/integration/consciousness/test_mea_bridge.py
    --ignore=tests/integration/consciousness/test_sensory_esgt_bridge.py

# Coverage configuration
[coverage:run]
source = .
omit =
    */tests/*
    */test_*.py
    */__pycache__/*
    */venv/*
    */env/*
    setup.py
    tests/archived_broken/*

[coverage:report]
precision = 2
show_missing = True
skip_covered = False

[coverage:html]
directory = htmlcov

# Markers for test categorization
markers =
    unit: Unit tests (fast, isolated)
    integration: Integration tests (medium speed, component interaction)
    e2e: End-to-end tests (slow, full workflow)
    slow: Slow tests (skip with -m 'not slow')
    benchmark: Performance benchmarks (biological plausibility validation)
    requires_torch: Tests requiring PyTorch
    requires_gpu: Tests requiring GPU
    requires_onnx: Tests requiring ONNX runtime
    requires_cuda: Tests requiring CUDA

# Console output styling
console_output_style = progress

# Timeout (10 minutes for slow tests)
timeout = 600

# Warnings
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning

# Logging
log_cli = false
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Pytest-xdist for parallel testing (if installed)
# Run with: pytest -n auto
# numprocesses = auto
