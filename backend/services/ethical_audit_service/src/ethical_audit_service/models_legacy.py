"""Pydantic Models for Ethical Audit Service.

This module defines the data models for ethical decisions, human overrides,
and compliance logs in the VÃ‰RTICE platform.
"""

from __future__ import annotations


import uuid
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field

# ============================================================================
# ENUMS
# ============================================================================


class DecisionType(str, Enum):
    """Types of decisions that require ethical evaluation."""

    OFFENSIVE_ACTION = "offensive_action"
    AUTO_RESPONSE = "auto_response"
    POLICY_UPDATE = "policy_update"
    DATA_ACCESS = "data_access"
    THREAT_MITIGATION = "threat_mitigation"
    RED_TEAM_OPERATION = "red_team_operation"


class FinalDecision(str, Enum):
    """Final decision outcomes."""

    APPROVED = "APPROVED"
    REJECTED = "REJECTED"
    ESCALATED_HITL = "ESCALATED_HITL"


class RiskLevel(str, Enum):
    """Risk levels for ethical decisions."""

    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


class OverrideReason(str, Enum):
    """Reasons for human override."""

    FALSE_POSITIVE = "false_positive"
    POLICY_EXCEPTION = "policy_exception"
    EMERGENCY = "emergency"
    ETHICAL_CONCERN = "ethical_concern"
    OPERATIONAL_NECESSITY = "operational_necessity"


class UrgencyLevel(str, Enum):
    """Urgency levels for overrides."""

    ROUTINE = "routine"
    URGENT = "urgent"
    CRITICAL = "critical"


class OperatorRole(str, Enum):
    """Operator roles in the system."""

    SOC_ANALYST = "SOC_ANALYST"
    SECURITY_ENGINEER = "SECURITY_ENGINEER"
    CHIEF_SECURITY_OFFICER = "CHIEF_SECURITY_OFFICER"
    ETHICS_OFFICER = "ETHICS_OFFICER"


class ComplianceResult(str, Enum):
    """Compliance check results."""

    COMPLIANT = "COMPLIANT"
    NON_COMPLIANT = "NON_COMPLIANT"
    PARTIAL = "PARTIAL"
    NOT_APPLICABLE = "NOT_APPLICABLE"


class Regulation(str, Enum):
    """Supported regulations."""

    EU_AI_ACT = "EU_AI_ACT"
    GDPR_ARTICLE_22 = "GDPR_ARTICLE_22"
    NIST_AI_RMF = "NIST_AI_RMF"
    TALLINN_MANUAL = "TALLINN_MANUAL"
    EXECUTIVE_ORDER_14110 = "EXECUTIVE_ORDER_14110"
    LGPD = "LGPD"  # Brazil


# ============================================================================
# FRAMEWORK RESULT MODELS
# ============================================================================


class FrameworkResult(BaseModel):
    """Result from a single ethical framework evaluation."""

    approved: bool
    confidence: float = Field(ge=0.0, le=1.0)
    veto: bool = False  # True if framework vetoes the decision
    explanation: str
    reasoning_steps: Optional[List[str]] = None
    latency_ms: Optional[int] = None


class KantianResult(FrameworkResult):
    """Kantian deontological framework result."""

    universalizability_passed: bool
    humanity_formula_passed: bool
    categorical_rules_violated: Optional[List[str]] = None


class ConsequentialistResult(FrameworkResult):
    """Consequentialist (utilitarian) framework result."""

    benefit_score: float
    cost_score: float
    net_utility: float
    fecundity_score: float  # Future prevention
    purity_score: float  # Absence of negative side effects
    stakeholders_analyzed: int


class VirtueEthicsResult(FrameworkResult):
    """Virtue ethics framework result."""

    virtues_assessed: Dict[str, float]  # {virtue_name: score}
    golden_mean_analysis: Optional[str] = None
    character_alignment: float  # Overall alignment with virtuous character


class PrinciplismResult(FrameworkResult):
    """Principialism framework result."""

    beneficence_score: float
    non_maleficence_score: float
    autonomy_score: float
    justice_score: float
    principle_conflicts: Optional[List[str]] = None


# ============================================================================
# ETHICAL DECISION MODELS
# ============================================================================


class EthicalDecisionRequest(BaseModel):
    """Request to evaluate an action ethically."""

    decision_type: DecisionType
    action_description: str = Field(min_length=10, max_length=2000)
    system_component: str
    input_context: Dict[str, Any]
    risk_level: RiskLevel
    session_id: Optional[uuid.UUID] = None
    operator_id: Optional[str] = None


class EthicalDecisionResponse(BaseModel):
    """Response from ethical evaluation."""

    decision_id: uuid.UUID
    timestamp: datetime
    decision_type: DecisionType
    action_description: str
    system_component: str

    # Framework results
    kantian_result: Optional[KantianResult] = None
    consequentialist_result: Optional[ConsequentialistResult] = None
    virtue_ethics_result: Optional[VirtueEthicsResult] = None
    principialism_result: Optional[PrinciplismResult] = None

    # Final decision
    final_decision: FinalDecision
    final_confidence: float = Field(ge=0.0, le=1.0)
    decision_explanation: str

    # Performance
    total_latency_ms: int
    risk_level: RiskLevel
    automated: bool

    class Config:
        json_encoders = {datetime: lambda v: v.isoformat(), uuid.UUID: lambda v: str(v)}


class EthicalDecisionLog(BaseModel):
    """Full log entry for audit database."""

    id: uuid.UUID = Field(default_factory=uuid.uuid4)
    timestamp: datetime = Field(default_factory=datetime.utcnow)
    decision_type: DecisionType
    action_description: str
    system_component: str
    input_context: Dict[str, Any]

    kantian_result: Optional[Dict[str, Any]] = None
    consequentialist_result: Optional[Dict[str, Any]] = None
    virtue_ethics_result: Optional[Dict[str, Any]] = None
    principialism_result: Optional[Dict[str, Any]] = None

    final_decision: FinalDecision
    final_confidence: float
    decision_explanation: str

    total_latency_ms: int
    kantian_latency_ms: Optional[int] = None
    consequentialist_latency_ms: Optional[int] = None
    virtue_ethics_latency_ms: Optional[int] = None
    principialism_latency_ms: Optional[int] = None

    risk_level: RiskLevel
    automated: bool = True
    operator_id: Optional[str] = None
    session_id: Optional[uuid.UUID] = None
    environment: str = "production"


# ============================================================================
# HUMAN OVERRIDE MODELS
# ============================================================================


class HumanOverrideRequest(BaseModel):
    """Request to log a human override."""

    decision_id: uuid.UUID
    operator_id: str
    operator_role: OperatorRole
    original_decision: FinalDecision
    override_decision: FinalDecision
    justification: str = Field(min_length=20, max_length=5000)
    override_reason: OverrideReason
    urgency_level: UrgencyLevel
    ip_address: Optional[str] = None
    user_agent: Optional[str] = None


class HumanOverrideResponse(BaseModel):
    """Response from logging a human override."""

    override_id: uuid.UUID
    decision_id: uuid.UUID
    timestamp: datetime
    operator_id: str
    operator_role: OperatorRole
    override_decision: FinalDecision
    justification: str
    override_reason: OverrideReason

    class Config:
        json_encoders = {datetime: lambda v: v.isoformat(), uuid.UUID: lambda v: str(v)}


# ============================================================================
# COMPLIANCE LOG MODELS
# ============================================================================


class ComplianceCheckRequest(BaseModel):
    """Request to log a compliance check."""

    regulation: Regulation
    requirement_id: str
    check_type: str  # 'automated', 'manual_review', 'third_party_audit'
    check_result: ComplianceResult
    evidence: Dict[str, Any]
    findings: Optional[str] = None
    decision_id: Optional[uuid.UUID] = None
    audit_cycle: Optional[str] = None
    auditor_id: Optional[str] = None

    # Remediation
    remediation_required: bool = False
    remediation_plan: Optional[str] = None
    remediation_deadline: Optional[datetime] = None


class ComplianceCheckResponse(BaseModel):
    """Response from logging a compliance check."""

    compliance_id: uuid.UUID
    timestamp: datetime
    regulation: Regulation
    requirement_id: str
    check_result: ComplianceResult
    remediation_required: bool

    class Config:
        json_encoders = {datetime: lambda v: v.isoformat(), uuid.UUID: lambda v: str(v)}


# ============================================================================
# METRICS & ANALYTICS MODELS
# ============================================================================


class EthicalMetrics(BaseModel):
    """Real-time ethical KPIs."""

    # Decision quality
    total_decisions_last_24h: int
    approval_rate: float
    rejection_rate: float
    hitl_escalation_rate: float

    # Performance
    avg_latency_ms: float
    p95_latency_ms: float
    p99_latency_ms: float

    # Framework agreement
    framework_agreement_rate: float  # % where all 4 frameworks agree
    kantian_veto_rate: float

    # Human override metrics
    total_overrides_last_24h: int
    override_rate: float
    override_reasons: Dict[str, int]

    # Compliance
    compliance_checks_last_week: int
    compliance_pass_rate: float
    critical_violations: int

    # Risk distribution
    risk_distribution: Dict[str, int]  # {low: 100, medium: 50, high: 20, critical: 5}


class FrameworkPerformance(BaseModel):
    """Performance metrics for a single framework."""

    framework_name: str
    total_decisions: int
    avg_latency_ms: float
    p95_latency_ms: float
    approval_rate: float
    avg_confidence: float


class DecisionHistoryQuery(BaseModel):
    """Query parameters for decision history."""

    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    decision_type: Optional[DecisionType] = None
    system_component: Optional[str] = None
    final_decision: Optional[FinalDecision] = None
    risk_level: Optional[RiskLevel] = None
    min_confidence: Optional[float] = Field(None, ge=0.0, le=1.0)
    max_confidence: Optional[float] = Field(None, ge=0.0, le=1.0)
    automated_only: Optional[bool] = None
    limit: int = Field(default=100, ge=1, le=1000)
    offset: int = Field(default=0, ge=0)


class DecisionHistoryResponse(BaseModel):
    """Response with decision history."""

    total_count: int
    decisions: List[EthicalDecisionResponse]
    query_time_ms: int

    class Config:
        json_encoders = {datetime: lambda v: v.isoformat(), uuid.UUID: lambda v: str(v)}
