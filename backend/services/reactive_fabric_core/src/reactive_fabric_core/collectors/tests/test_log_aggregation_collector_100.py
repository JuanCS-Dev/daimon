"""
Additional tests for Log Aggregation Collector to achieve 100% coverage.

Tests edge cases and error paths not covered by main test suite.
"""

from __future__ import annotations


from datetime import datetime, timedelta
from unittest.mock import AsyncMock, patch

import pytest
from aioresponses import aioresponses

from ..log_aggregation_collector import (
    LogAggregationCollector,
    LogAggregationConfig
)
from ..base_collector import CollectedEvent


class TestFullCoverage:
    """Additional tests for 100% coverage."""

    @pytest.mark.asyncio
    async def test_elasticsearch_api_key_auth(self):
        """Test Elasticsearch with API key authentication."""
        config = LogAggregationConfig(
            backend_type="elasticsearch",
            api_key="test_api_key"
        )
        collector = LogAggregationCollector(config)
        await collector.initialize()

        assert collector.session is not None
        assert "Authorization" in collector.session.headers
        assert collector.session.headers["Authorization"] == "ApiKey test_api_key"

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_splunk_api_key_auth(self):
        """Test Splunk with API key authentication."""
        config = LogAggregationConfig(
            backend_type="splunk",
            api_key="test_api_key"
        )
        collector = LogAggregationCollector(config)
        await collector.initialize()

        assert collector.session is not None
        assert "Authorization" in collector.session.headers
        assert collector.session.headers["Authorization"] == "Bearer test_api_key"

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_validate_source_splunk(self):
        """Test Splunk source validation."""
        config = LogAggregationConfig(backend_type="splunk")
        collector = LogAggregationCollector(config)
        await collector.initialize()

        with aioresponses() as mock:
            mock.get(
                "https://localhost:9200/services/server/info",
                status=200,
                payload={"entry": [{"name": "server"}]}
            )

            is_valid = await collector.validate_source()
            assert is_valid is True

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_validate_source_graylog(self):
        """Test Graylog source validation."""
        config = LogAggregationConfig(backend_type="graylog")
        collector = LogAggregationCollector(config)
        await collector.initialize()

        with aioresponses() as mock:
            mock.get(
                "http://localhost:9200/api/system/cluster",
                status=200,
                payload={"cluster_id": "test"}
            )

            is_valid = await collector.validate_source()
            assert is_valid is True

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_validate_source_unknown_backend(self):
        """Test validation with invalid backend type."""
        config = LogAggregationConfig(backend_type="elasticsearch")
        collector = LogAggregationCollector(config)
        collector.config.backend_type = "unknown"  # Force invalid backend
        await collector.initialize()

        is_valid = await collector.validate_source()
        assert is_valid is False

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_validate_source_exception(self):
        """Test validation when exception occurs."""
        config = LogAggregationConfig(backend_type="elasticsearch")
        collector = LogAggregationCollector(config)
        await collector.initialize()

        with aioresponses() as mock:
            # Don't mock the endpoint - will cause connection error
            pass

        is_valid = await collector.validate_source()
        assert is_valid is False

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_collect_with_exception_in_backend_check(self):
        """Test collect when backend type check throws exception."""
        config = LogAggregationConfig(backend_type="elasticsearch")
        collector = LogAggregationCollector(config)
        await collector.initialize()

        # Force an invalid backend to trigger else paths
        original_backend = collector.config.backend_type
        collector.config.backend_type = "invalid"

        events = []
        async for event in collector.collect():
            events.append(event)

        assert len(events) == 0
        # Error count is incremented in the collect method, not in sub-methods

        collector.config.backend_type = original_backend
        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_collect_splunk_no_sid(self):
        """Test Splunk collection when no SID is returned."""
        config = LogAggregationConfig(backend_type="splunk")
        collector = LogAggregationCollector(config)
        await collector.initialize()

        with aioresponses() as mock:
            # Mock job creation without SID
            mock.post(
                "https://localhost:9200/services/search/jobs",
                status=201,
                payload={}  # No SID
            )

            events = []
            async for event in collector.collect():
                events.append(event)

            assert len(events) == 0

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_collect_splunk_failed_job(self):
        """Test Splunk collection when job creation fails."""
        config = LogAggregationConfig(backend_type="splunk")
        collector = LogAggregationCollector(config)
        await collector.initialize()

        with aioresponses() as mock:
            # Mock failed job creation
            mock.post(
                "https://localhost:9200/services/search/jobs",
                status=400,
                body="Bad Request"
            )

            events = []
            async for event in collector.collect():
                events.append(event)

            assert len(events) == 0

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_collect_splunk_failed_results(self):
        """Test Splunk collection when results fetch fails."""
        config = LogAggregationConfig(backend_type="splunk")
        collector = LogAggregationCollector(config)
        await collector.initialize()

        with aioresponses() as mock:
            # Mock successful job creation
            mock.post(
                "https://localhost:9200/services/search/jobs",
                status=201,
                payload={"sid": "job123"}
            )

            # Mock failed results fetch
            mock.get(
                "https://localhost:9200/services/search/jobs/job123/results?output_mode=json",
                status=404,
                body="Not Found"
            )

            events = []
            async for event in collector.collect():
                events.append(event)

            assert len(events) == 0

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_collect_splunk_exception(self):
        """Test Splunk collection with exception."""
        config = LogAggregationConfig(backend_type="splunk")
        collector = LogAggregationCollector(config)
        await collector.initialize()

        # Don't mock anything - will cause connection error
        events = []
        async for event in collector.collect():
            events.append(event)

        assert len(events) == 0

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_collect_graylog_exception(self):
        """Test Graylog collection with exception."""
        config = LogAggregationConfig(backend_type="graylog")
        collector = LogAggregationCollector(config)
        await collector.initialize()

        # Don't mock anything - will cause connection error
        events = []
        async for event in collector.collect():
            events.append(event)

        assert len(events) == 0

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_collect_without_session(self):
        """Test collection when session is not initialized."""
        config = LogAggregationConfig(backend_type="elasticsearch")
        collector = LogAggregationCollector(config)
        # Don't initialize - no session

        events = []
        async for event in collector._collect_elasticsearch(
            datetime.utcnow(),
            datetime.utcnow()
        ):
            events.append(event)

        assert len(events) == 0

    @pytest.mark.asyncio
    async def test_parse_elasticsearch_hit_no_pattern_match(self):
        """Test parsing Elasticsearch hit with no pattern match."""
        config = LogAggregationConfig()
        collector = LogAggregationCollector(config)

        hit = {
            "_index": "logs-2024",
            "_id": "test123",
            "_source": {
                "message": "Normal log message with no security patterns"
            }
        }

        event = await collector._parse_elasticsearch_hit(hit)
        assert event is None

    @pytest.mark.asyncio
    async def test_parse_elasticsearch_hit_exception(self):
        """Test parsing Elasticsearch hit with exception."""
        config = LogAggregationConfig()
        collector = LogAggregationCollector(config)

        # Invalid hit structure to cause exception
        hit = None

        event = await collector._parse_elasticsearch_hit(hit)
        assert event is None

    @pytest.mark.asyncio
    async def test_parse_splunk_result_no_pattern_match(self):
        """Test parsing Splunk result with no pattern match."""
        config = LogAggregationConfig()
        collector = LogAggregationCollector(config)

        result = {
            "_raw": "Normal log message with no security patterns",
            "index": "main"
        }

        event = await collector._parse_splunk_result(result)
        assert event is None

    @pytest.mark.asyncio
    async def test_parse_splunk_result_exception(self):
        """Test parsing Splunk result with exception."""
        config = LogAggregationConfig()
        collector = LogAggregationCollector(config)

        # Invalid result structure to cause exception
        result = None

        event = await collector._parse_splunk_result(result)
        assert event is None

    @pytest.mark.asyncio
    async def test_parse_graylog_message_no_pattern_match(self):
        """Test parsing Graylog message with no pattern match."""
        config = LogAggregationConfig()
        collector = LogAggregationCollector(config)

        message = {
            "message": {
                "message": "Normal log message with no security patterns"
            },
            "index": "graylog_0"
        }

        event = await collector._parse_graylog_message(message)
        assert event is None

    @pytest.mark.asyncio
    async def test_parse_graylog_message_exception(self):
        """Test parsing Graylog message with exception."""
        config = LogAggregationConfig()
        collector = LogAggregationCollector(config)

        # Invalid message structure to cause exception
        message = None

        event = await collector._parse_graylog_message(message)
        assert event is None

    @pytest.mark.asyncio
    async def test_collect_elasticsearch_exception(self):
        """Test Elasticsearch collection with exception."""
        config = LogAggregationConfig(backend_type="elasticsearch")
        collector = LogAggregationCollector(config)
        await collector.initialize()

        # Mock to throw exception
        with patch.object(collector.session, 'post', side_effect=Exception("Test error")):
            events = []
            async for event in collector._collect_elasticsearch(
                datetime.utcnow(),
                datetime.utcnow()
            ):
                events.append(event)

            assert len(events) == 0

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_cleanup_without_session(self):
        """Test cleanup when session doesn't exist."""
        config = LogAggregationConfig()
        collector = LogAggregationCollector(config)

        # Cleanup without initialization
        await collector.cleanup()
        assert collector.session is None

    @pytest.mark.asyncio
    async def test_validate_source_without_session(self):
        """Test validation when session is not initialized."""
        config = LogAggregationConfig(backend_type="elasticsearch")
        collector = LogAggregationCollector(config)
        # Don't initialize - no session

        is_valid = await collector.validate_source()
        assert is_valid is False

    @pytest.mark.asyncio
    async def test_collect_graylog_full_flow(self):
        """Test full Graylog collection flow with actual network call."""
        config = LogAggregationConfig(backend_type="graylog")
        collector = LogAggregationCollector(config)
        await collector.initialize()

        # Test parsing directly since aioresponses has issues with query params
        messages = [
            {
                "message": {
                    "message": "sudo command executed",
                    "timestamp": "2024-01-01T10:00:00.000Z"
                },
                "index": "graylog_0"
            }
        ]

        events = []
        for message in messages:
            event = await collector._parse_graylog_message(message)
            if event:
                events.append(event)

        assert len(events) == 1

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_collect_graylog_with_error_response(self):
        """Test Graylog collection with error response."""
        config = LogAggregationConfig(backend_type="graylog")
        collector = LogAggregationCollector(config)
        await collector.initialize()

        with aioresponses() as mock:
            mock.get(
                "http://localhost:9200/api/search/universal/relative",
                status=500,
                body="Internal Server Error"
            )

            events = []
            async for event in collector._collect_graylog(
                datetime.utcnow() - timedelta(minutes=5),
                datetime.utcnow()
            ):
                events.append(event)

            assert len(events) == 0

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_collect_splunk_without_session(self):
        """Test Splunk collection when session is not initialized."""
        config = LogAggregationConfig(backend_type="splunk")
        collector = LogAggregationCollector(config)
        # Don't initialize - no session

        events = []
        async for event in collector._collect_splunk(
            datetime.utcnow(),
            datetime.utcnow()
        ):
            events.append(event)

        assert len(events) == 0

    @pytest.mark.asyncio
    async def test_collect_graylog_without_session(self):
        """Test Graylog collection when session is not initialized."""
        config = LogAggregationConfig(backend_type="graylog")
        collector = LogAggregationCollector(config)
        # Don't initialize - no session

        events = []
        async for event in collector._collect_graylog(
            datetime.utcnow(),
            datetime.utcnow()
        ):
            events.append(event)

        assert len(events) == 0

    @pytest.mark.asyncio
    async def test_collect_main_graylog_backend(self):
        """Test main collect() method with Graylog backend (line 237)."""
        config = LogAggregationConfig(backend_type="graylog")
        collector = LogAggregationCollector(config)
        await collector.initialize()

        # Patch _collect_graylog directly to test the yield in collect()
        async def mock_collect_graylog(from_time, to_time):
            # Yield a test event
            yield CollectedEvent(
                collector_type="LogAggregation",
                source="graylog:test",
                severity="high",
                raw_data={"message": "test"},
                parsed_data={"pattern_name": "privilege_escalation"},
                tags=["test"]
            )

        with patch.object(collector, '_collect_graylog', mock_collect_graylog):
            events = []
            async for event in collector.collect():
                events.append(event)

            # Should have one event that was yielded
            assert len(events) == 1
            assert events[0].parsed_data["pattern_name"] == "privilege_escalation"

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_collect_main_exception_handling(self):
        """Test exception handling in main collect() method (lines 242-244)."""
        config = LogAggregationConfig(backend_type="elasticsearch")
        collector = LogAggregationCollector(config)
        await collector.initialize()

        # Force an exception by patching the specific backend method
        with patch.object(collector, '_collect_elasticsearch', side_effect=Exception("Test error")):
            initial_errors = collector.metrics.errors_count

            events = []
            async for event in collector.collect():
                events.append(event)

            assert len(events) == 0
            assert collector.metrics.errors_count == initial_errors + 1

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_collect_graylog_http_error(self):
        """Test Graylog collection with HTTP error response (line 485)."""
        config = LogAggregationConfig(backend_type="graylog")
        collector = LogAggregationCollector(config)
        await collector.initialize()

        # Mock response with non-200 status
        mock_response = AsyncMock()
        mock_response.status = 404  # This will trigger the early return on line 485
        mock_response.__aenter__ = AsyncMock(return_value=mock_response)
        mock_response.__aexit__ = AsyncMock(return_value=None)

        with patch.object(collector.session, 'get', return_value=mock_response):
            events = []
            async for event in collector._collect_graylog(
                datetime.utcnow() - timedelta(minutes=5),
                datetime.utcnow()
            ):
                events.append(event)

            assert len(events) == 0

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_collect_graylog_successful_with_messages(self):
        """Test Graylog collection success path with actual messages (lines 487-491)."""
        config = LogAggregationConfig(backend_type="graylog")
        collector = LogAggregationCollector(config)
        await collector.initialize()

        # Patch the session.get method to simulate successful response
        mock_response = AsyncMock()
        mock_response.status = 200
        mock_response.json = AsyncMock(return_value={
            "messages": [
                {
                    "message": {
                        "message": "malware detected on system",
                        "timestamp": "2024-01-01T10:00:00Z"
                    },
                    "index": "graylog_0"
                },
                {
                    "message": {
                        "message": "port scan detected from 192.168.1.1",
                        "timestamp": "2024-01-01T10:05:00Z"
                    },
                    "index": "graylog_0"
                }
            ]
        })
        mock_response.__aenter__ = AsyncMock(return_value=mock_response)
        mock_response.__aexit__ = AsyncMock(return_value=None)

        with patch.object(collector.session, 'get', return_value=mock_response) as mock_get:
            events = []
            async for event in collector._collect_graylog(
                datetime.utcnow() - timedelta(minutes=5),
                datetime.utcnow()
            ):
                events.append(event)

            assert len(events) == 2
            assert events[0].parsed_data["pattern_name"] == "malware_indicators"
            assert events[1].parsed_data["pattern_name"] == "network_scanning"

        await collector.cleanup()

    @pytest.mark.asyncio
    async def test_collect_graylog_json_parse_error(self):
        """Test Graylog collection with invalid JSON response (lines 493-494)."""
        config = LogAggregationConfig(backend_type="graylog")
        collector = LogAggregationCollector(config)
        await collector.initialize()

        with aioresponses() as mock:
            # Mock response with invalid JSON to trigger exception
            mock.get(
                "http://localhost:9200/api/search/universal/relative",
                status=200,
                body="Invalid JSON {["
            )

            events = []
            async for event in collector._collect_graylog(
                datetime.utcnow() - timedelta(minutes=5),
                datetime.utcnow()
            ):
                events.append(event)

            assert len(events) == 0

        await collector.cleanup()