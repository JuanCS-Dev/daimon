# Nebius Token Factory Integration

> **Status**: ‚úÖ Operational (Dezembro 2025)  
> **Provider**: [Nebius Token Factory](https://tokenfactory.nebius.com)  
> **API Docs**: https://docs.tokenfactory.nebius.com/quickstart  
> **Cookbook**: https://github.com/nebius/token-factory-cookbook

## Overview

Noesis/Daimon utiliza o **Nebius Token Factory** como provider prim√°rio de LLM, oferecendo:

- üöÄ **API compat√≠vel com OpenAI** - Zero refactoring
- üí∞ **Custo-efetivo** - Modelos open-source a pre√ßos competitivos
- üß† **DeepSeek-R1** - Modelo de racioc√≠nio ideal para metacogni√ß√£o
- ‚ö° **Baixa lat√™ncia** - < 2s para primeira resposta

## Modelos Dispon√≠veis

### Reasoning (Recomendado para Metacogni√ß√£o)

| Modelo | ID | Uso |
|--------|-----|-----|
| DeepSeek-R1 | `deepseek-ai/DeepSeek-R1-0528` | **Default** - Tribunal, judges |
| DeepSeek-V3 | `deepseek-ai/DeepSeek-V3-0324` | General reasoning |

### Large Context

| Modelo | ID | Contexto |
|--------|-----|----------|
| Qwen3-235B | `Qwen/Qwen3-235B-A22B` | 128k tokens |
| Qwen2.5-72B | `Qwen/Qwen2.5-72B-Instruct` | 32k tokens |

### Fast Inference

| Modelo | ID | Uso |
|--------|-----|-----|
| Llama-3.3-70B | `meta-llama/Llama-3.3-70B-Instruct` | Chat, quick responses |
| Llama-3.1-8B | `meta-llama/Meta-Llama-3.1-8B-Instruct` | Lightweight tasks |

## Configura√ß√£o

### 1. Obter API Key

1. Acesse https://tokenfactory.nebius.com
2. Fa√ßa login com Google ou GitHub
3. Gere uma API Key em "API Keys"

### 2. Configurar `.env`

```bash
# Provider selection
LLM_PROVIDER=nebius

# Nebius Token Factory
NEBIUS_API_KEY=v1.CmMKHHN0YX...your_key_here
NEBIUS_MODEL=deepseek-ai/DeepSeek-R1-0528

# Optional: Gemini fallback
# GEMINI_API_KEY=your_gemini_key
```

### 3. Usar no C√≥digo

```python
from metacognitive_reflector.llm import get_llm_client

# Obter cliente (singleton)
client = get_llm_client()

# Gera√ß√£o simples
response = await client.generate("What is consciousness?")
print(response.text)

# Chat format (para judges)
response = await client.chat([
    {"role": "system", "content": "You are VERITAS, judge of truth."},
    {"role": "user", "content": "Evaluate this claim..."}
])
```

## Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              UnifiedLLMClient                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Nebius (Primary) ‚îÇ  ‚îÇ  Gemini (Fallback)  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  OpenAI API       ‚îÇ  ‚îÇ  Native API         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  DeepSeek-R1      ‚îÇ  ‚îÇ  Gemini 2.0         ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ           ‚Üì Auto-retry, Cache, Stats            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚ñº                           ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ   VERITAS    ‚îÇ           ‚îÇ   SOPHIA     ‚îÇ
   ‚îÇ   (Truth)    ‚îÇ           ‚îÇ   (Wisdom)   ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Features

### Response Caching

Respostas s√£o cacheadas por 5 minutos para reduzir custos:

```python
# Primeira chamada - API request
response1 = await client.generate("What is truth?")
print(response1.cached)  # False

# Segunda chamada - Cache hit
response2 = await client.generate("What is truth?")
print(response2.cached)  # True
print(response2.latency_ms)  # 0.0
```

### Automatic Retries

3 tentativas com exponential backoff em caso de erro:

```python
# Configur√°vel via LLMConfig
config = LLMConfig(
    retry_attempts=3,
    retry_delay=1.0,  # segundos
)
```

### Statistics

```python
stats = client.stats
print(stats)
# {
#     "provider": "nebius",
#     "total_requests": 42,
#     "total_tokens": 15000,
#     "cache_hits": 12,
#     "cache_hit_rate": 0.22
# }
```

### Health Check

```python
health = await client.health_check()
# {
#     "healthy": True,
#     "provider": "nebius",
#     "model": "deepseek-ai/DeepSeek-R1-0528",
#     "latency_ms": 1750.5
# }
```

## DeepSeek-R1: Modelo de Racioc√≠nio

O DeepSeek-R1 √© particularmente adequado para o pipeline metacognitivo porque:

1. **Racioc√≠nio Expl√≠cito** - Usa tags `<think>` para mostrar o processo de pensamento
2. **Auto-reflex√£o** - Capaz de avaliar suas pr√≥prias conclus√µes
3. **An√°lise Multi-etapa** - Ideal para os judges (VERITAS, SOPHIA, DIKƒí)

### Exemplo de Resposta

```
<think>
Hmm, the user is asking me to evaluate a claim about truth...
Let me analyze this step by step:
1. First, I need to identify the factual claims...
2. Then, cross-reference with known facts...
3. Finally, assess confidence level...
</think>

VERDICT: FALSE
CONFIDENCE: 0.95
REASONING: The claim contradicts established scientific consensus...
```

## Troubleshooting

### "NEBIUS_API_KEY not set"

Verifique se a chave est√° no `.env` e que o arquivo est√° sendo carregado:

```bash
# Verificar .env
cat .env | grep NEBIUS

# Exportar manualmente
export NEBIUS_API_KEY=v1.CmM...
```

### "401 Unauthorized"

A API key pode estar inv√°lida ou expirada. Gere uma nova em https://tokenfactory.nebius.com

### "Model not found"

Verifique se o modelo est√° correto. Lista completa:
https://docs.tokenfactory.nebius.com/models

## Testes

```bash
# Teste r√°pido
cd backend/services/metacognitive_reflector
python tests/test_nebius_integration.py

# Suite completa
pytest tests/test_nebius_integration.py -v
```

## Custo Estimado

| Modelo | Input (1M tokens) | Output (1M tokens) |
|--------|-------------------|-------------------|
| DeepSeek-R1 | ~$2.00 | ~$8.00 |
| Llama-3.3-70B | ~$0.50 | ~$0.50 |
| Qwen2.5-72B | ~$0.80 | ~$0.80 |

*Pre√ßos aproximados - verificar em tokenfactory.nebius.com*

## Refer√™ncias

- [Nebius Token Factory Docs](https://docs.tokenfactory.nebius.com)
- [Nebius Cookbook](https://github.com/nebius/token-factory-cookbook)
- [DeepSeek-R1 Paper](https://arxiv.org/abs/2401.02954)

